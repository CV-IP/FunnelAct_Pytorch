{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import resnet_frelu as resnet\n",
    "import os\n",
    "from main import AverageMeter, ProgressMeter, accuracy, train, validate\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Validate current set of weights</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('frelu_resnet50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'C://ImageNet/'\n",
    "traindir = os.path.join(data, 'train')\n",
    "valdir = os.path.join(data, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "total_steps = 300000\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "train_dataset = datasets.ImageFolder(traindir,\n",
    "                                     transforms.Compose([\n",
    "                                         transforms.RandomResizedCrop(224),\n",
    "                                         transforms.RandomHorizontalFlip(),\n",
    "                                         transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         normalize\n",
    "                                        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "                                datasets.ImageFolder(valdir, transforms.Compose([\n",
    "                                    transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    normalize\n",
    "                                ])),\n",
    "                                batch_size=100, shuffle=True,\n",
    "                                num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [  0/500]\tTime  5.682 ( 5.682)\tLoss 7.2411e-01 (7.2411e-01)\tAcc@1  85.00 ( 85.00)\tAcc@5  97.00 ( 97.00)\n",
      "Test: [100/500]\tTime  0.553 ( 0.602)\tLoss 8.2409e-01 (9.4904e-01)\tAcc@1  78.00 ( 77.50)\tAcc@5  95.00 ( 93.64)\n",
      "Test: [200/500]\tTime  0.559 ( 0.579)\tLoss 7.7373e-01 (9.3647e-01)\tAcc@1  84.00 ( 77.70)\tAcc@5  94.00 ( 93.80)\n",
      "Test: [300/500]\tTime  0.555 ( 0.573)\tLoss 1.3577e+00 (9.4489e-01)\tAcc@1  74.00 ( 77.42)\tAcc@5  90.00 ( 93.77)\n",
      "Test: [400/500]\tTime  0.559 ( 0.571)\tLoss 9.4712e-01 (9.3480e-01)\tAcc@1  81.00 ( 77.57)\tAcc@5  95.00 ( 93.87)\n",
      " * Acc@1 77.606 Acc@5 93.836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(77.6060, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()\n",
    "validate(val_loader, model, criterion, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create and train new ResNet with FReLU activations (primitive example)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet.resnet101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate / 10,\n",
    "        momentum=0.9,\n",
    "        weight_decay=1e-4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "train_sampler = None\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=4, shuffle=(train_sampler is None),\n",
    "        num_workers=1, pin_memory=True, sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in range(10):\n",
    "    train(train_loader, model, criterion, optimizer, e)\n",
    "    torch.save(model, 'FResNet50_' + str(e) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
